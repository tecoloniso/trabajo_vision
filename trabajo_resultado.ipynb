{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from skimage.segmentation import slic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrarHistograma(imagen, ax=None, etiqueta=None):\n",
    "    imagen = np.uint8(imagen)  # Asegurarse de que la imagen esté en formato uint8\n",
    "    histograma = cv2.calcHist([imagen], [0], None, [256], [0, 256])\n",
    "    #histograma = histograma / histograma.max()  # Normalizar el histograma para que no se sobrepasen los límites\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    ax.plot(np.arange(256), histograma[:, 0],label=etiqueta)\n",
    "    ax.set_xlim(0, 255)  # Asegurar que el eje X esté entre 0 y 255\n",
    "\n",
    "def muestra(imagen):\n",
    "    cv2.imshow('',imagen)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def analisisImagen(imagen):\n",
    "    media = np.mean(imagen)\n",
    "    desviacion = np.std(imagen)\n",
    "    max = np.max(imagen)\n",
    "    min = np.min(imagen)\n",
    "\n",
    "    analisis = {\n",
    "        'media': media,\n",
    "        'std': desviacion,\n",
    "        'min': min,\n",
    "        'max': max,\n",
    "        'contraste': max-min\n",
    "    }\n",
    "\n",
    "    return analisis\n",
    "\n",
    "def modificarImagen(imagen,n):\n",
    "    imagen_modificada = cv2.resize(imagen, (n, n), interpolation=cv2.INTER_AREA)    \n",
    "    return np.uint8(imagen_modificada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolucion = 280\n",
    "\n",
    "def prepro_rango_dinamico(nueva):\n",
    "    #Ampliacion del rango dinamico\n",
    "    nueva = np.float32(nueva)\n",
    "    r1 = np.min(nueva)\n",
    "    r2 = np.max(nueva)\n",
    "    if r2-r1 < 100:\n",
    "        nueva = 255 * (nueva - r1) / (r2 - r1)\n",
    "    return np.uint8(nueva)\n",
    "\n",
    "def prepro_ecualizacion_histograma(nueva):\n",
    "    #Ecualizacion del histograma\n",
    "    return cv2.equalizeHist(nueva)\n",
    "\n",
    "def prepro_suavizado(nueva):\n",
    "    H = np.ones((5, 5), dtype=np.float32) / 25\n",
    "    nueva = cv2.filter2D(nueva, -1, H)\n",
    "    return np.uint8(nueva)\n",
    "\n",
    "def prepro_gamma(imagen, gamma):\n",
    "    tabla = np.array([((i / 255.0) ** gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(imagen, tabla)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocesamiento(imagen): # seleccion automatica\n",
    "\n",
    "    analisis = analisisImagen(imagen)\n",
    "    if analisis['std'] > 50:\n",
    "        imagen = prepro_suavizado(imagen)\n",
    "        \n",
    "    analisis = analisisImagen(imagen)\n",
    "    if analisis['contraste'] < 200:\n",
    "        imagen = prepro_rango_dinamico(imagen)\n",
    "        imagen = prepro_ecualizacion_histograma(imagen)\n",
    "\n",
    "    analisis = analisisImagen(imagen)\n",
    "    if analisis['media'] > 180:\n",
    "        imagen = prepro_gamma(imagen, 2.0)\n",
    "    elif analisis['media'] < 70:\n",
    "        imagen = prepro_gamma(imagen, 0.5)\n",
    "\n",
    "    return modificarImagen(imagen,resolucion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraccionCaracteristicasPuntosEspacial(imagen,num):\n",
    "    mask = puntosSingulares(imagen)\n",
    "    coordenadas = np.argwhere(mask == 1)\n",
    "\n",
    "    h, w = imagen.shape\n",
    "    hist = np.zeros((num, num))\n",
    "\n",
    "    for y, x in coordenadas:\n",
    "\n",
    "        grid_y, grid_x = y * num // h, x * num // w\n",
    "\n",
    "        hist[grid_y, grid_x] += 1\n",
    "    \n",
    "    feature_vector = hist.flatten()\n",
    "    feature_vector = feature_vector / np.linalg.norm(feature_vector)\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "def puntosSingulares(imagen):\n",
    "    imagen = np.float32(imagen)\n",
    "    dst = cv2.cornerHarris(imagen,2,3,0.04)\n",
    "    dst = cv2.dilate(dst,None)\n",
    "    mask = (dst>0.01*dst.max())\n",
    " \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogramasXceldas(imagen, num, E, phi):\n",
    "    filas, columnas = imagen.shape\n",
    "    histogramas = []\n",
    "    for i in range(0, filas, num):\n",
    "        for j in range(0, filas, num):\n",
    "            celdaMag = E[i:i+num,j:j+num].flatten()\n",
    "            celdaOri = phi[i:i+num,j:j+num].flatten()\n",
    "            h = np.zeros(9)\n",
    "            indices = celdaOri//(360//9)\n",
    "            \n",
    "            h = np.bincount(indices, weights=celdaMag, minlength=9)\n",
    "            \n",
    "            h = h/(np.sqrt(np.sum(h ** 2))+1e-6)\n",
    "            histogramas.append(h)\n",
    "    return histogramas\n",
    "\n",
    "def gradiente(imagen):\n",
    "    imagen_x = cv2.Sobel(imagen, cv2.CV_32F,1,0,ksize = 1)\n",
    "    imagen_y = cv2.Sobel(imagen, cv2.CV_32F,0,1,ksize = 1)\n",
    "\n",
    "    E = np.sqrt(np.power(imagen_x, 2) + np.power(imagen_y, 2))\n",
    "    Phi = np.arctan2(imagen_y, imagen_x)\n",
    "    Phi = np.rad2deg(Phi)\n",
    "\n",
    "    return np.uint8(E), np.uint8(Phi)\n",
    "\n",
    "def extraccionCaracteristicas(imagen, num):\n",
    "    imagen = np.float32(imagen)\n",
    "    E, phi = gradiente(imagen)\n",
    "    caracteristicas = np.concatenate(histogramasXceldas(imagen, num, E, phi))\n",
    "    return caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_imagenes_y_labels(pathfile, preprocesamiento, extractor):\n",
    "    X, y = [], []\n",
    "    clases = ['cat', 'dog']\n",
    "\n",
    "    for clase in clases:\n",
    "        ruta = os.path.join(pathfile, clase)\n",
    "        archivos = glob.glob(os.path.join(ruta, \"*.jpg\"))\n",
    "        for archivo in archivos:\n",
    "            imagen = cv2.imread(archivo, 0)\n",
    "            imagen = preprocesamiento(imagen)\n",
    "            caracteristicas = extractor(imagen,16)\n",
    "            X.append(caracteristicas)\n",
    "            y.append(0 if clase == 'cat' else 1)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8100\n"
     ]
    }
   ],
   "source": [
    "mejor_combinacion = [preprocesamiento, extraccionCaracteristicasPuntosEspacial]\n",
    "mejor_modelo = make_pipeline(StandardScaler(), MLPClassifier(max_iter=200, random_state=41))\n",
    "param_grid = {\n",
    "    'mlpclassifier__hidden_layer_sizes': [(50,)],\n",
    "    'mlpclassifier__activation': ['relu']\n",
    "}\n",
    "def evaluar(dataset_path,mejor_combinacion,mejor_modelo,param_grid):\n",
    "\n",
    "    # Cargar datos de entrenamiento desde la carpeta train\n",
    "    X_train, y_train = cargar_imagenes_y_labels(os.path.join(dataset_path, 'train'), mejor_combinacion[0], mejor_combinacion[1])\n",
    "    # Cargar datos de prueba desde la carpeta test\n",
    "    X_test, y_test = cargar_imagenes_y_labels(os.path.join(dataset_path, 'test'), mejor_combinacion[0], mejor_combinacion[1])\n",
    "\n",
    "    # Entrenar modelo\n",
    "    grid_search = GridSearchCV(mejor_modelo, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar modelo\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "evaluar('dataset/cat_dog_500',mejor_combinacion,mejor_modelo,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.835"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "mejor_combinacion = [preprocesamiento, extraccionCaracteristicasPuntosEspacial]\n",
    "estimator = DecisionTreeClassifier(criterion='entropy')\n",
    "mejor_modelo = make_pipeline(StandardScaler(), BaggingClassifier(estimator, n_estimators=15, random_state=42))\n",
    "param_grid = {\n",
    "    'mlpclassifier__hidden_layer_sizes': [(50,)],\n",
    "    'mlpclassifier__activation': ['relu']\n",
    "}\n",
    "def evaluar(dataset_path,mejor_combinacion,mejor_modelo,param_grid):\n",
    "\n",
    "    # Cargar datos de entrenamiento desde la carpeta train\n",
    "    X_train, y_train = cargar_imagenes_y_labels(os.path.join(dataset_path, 'train'), mejor_combinacion[0], mejor_combinacion[1])\n",
    "    # Cargar datos de prueba desde la carpeta test\n",
    "    X_test, y_test = cargar_imagenes_y_labels(os.path.join(dataset_path, 'test'), mejor_combinacion[0], mejor_combinacion[1])\n",
    "\n",
    "    # Entrenar modelo\n",
    "    #grid_search = GridSearchCV(mejor_modelo, param_grid=None, cv=3, scoring='accuracy', n_jobs=-1) \n",
    "    mejor_modelo.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar modelo\n",
    "    y_pred = mejor_modelo.predict(X_test)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "evaluar('dataset/cat_dog_500',mejor_combinacion,mejor_modelo,param_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
